{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Objetivos__:\n",
    "\n",
    "- Implementar as principais funções de ativação\n",
    "- Entender intuitivamente como $w$ e $b$ influenciam nas funções de ativação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sumário"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Linear](#Linear)\n",
    "- [Sigmoid](#Sigmoid)\n",
    "- [Tanh](#Tanh)\n",
    "- [Rectified Linear Unit (ReLU)](#Rectified-Linear-Unit-(ReLU))\n",
    "- [Leaky ReLU](#Leaky-ReLU)\n",
    "- [Exponential Linear Unit (eLU)](#Exponential-Linear-Unit-(eLU))\n",
    "- [Tabela das Funções de Ativação](#Tabela-das-Funções-de-Ativação)\n",
    "- [Referências](#Referências)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as wg\n",
    "from ipywidgets import interactive, fixed\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_interactive(w, b, func, ylim=fixed((0, 1)), show_der=False):\n",
    "    plt.figure(0)\n",
    "    \n",
    "    x = np.linspace(-10, 10, num=1000)\n",
    "    z = w*x + b\n",
    "    y = func(z)\n",
    "    \n",
    "    plt.plot(x, y, color='blue')\n",
    "    if show_der:\n",
    "        der = func(z, derivative=True)\n",
    "        y_der_z = der\n",
    "        y_der_x = w*der\n",
    "        plt.plot(x, y_der_z, color='red')\n",
    "        plt.plot(x, y_der_x, color='green')\n",
    "    plt.xlim(-10, 10)\n",
    "    plt.ylim(ylim[0], ylim[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y=x$$\n",
    "\n",
    "$$y^\\prime = 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, derivative=False):\n",
    "    return np.ones_like(x) if derivative else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d63748a3cfe450093e30777709f2c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=2.0, min=-2.0), FloatSlider(value=0.0, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plot = interactive(\n",
    "    plot_interactive, \n",
    "    w=(-2.0, 2.0), \n",
    "    b=(-3, 3, 0.5), \n",
    "    func=fixed(linear),\n",
    "    ylim=fixed((-10, 10))\n",
    ")\n",
    "# red: derivative = 1\n",
    "# green: derivative = w*1\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "$$y^\\prime = y(1-y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$1+e^{-x} = \\frac{1}{y} \\implies e^{-x} = \\frac{1}{y} - 1 = \\frac{1-y}{y}  $$\n",
    "\n",
    "$$\n",
    "y^\\prime = \\frac{d}{dx}(1+e^{-x})^{-1} = (-1)(1+e^{-x})^{-1-1}(-1)e^{-x} = \\frac{e^{-x}}{(1+e^{-x})^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "y^\\prime = e^{-x} \\frac{1}{(1+e^{-x})^2} = \\frac{1-y}{y} y^2 = y(1-y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    y = 1.0 / (1.0 + np.exp(-x))\n",
    "    return y*(1-y) if derivative else y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06079da0f69f4b8f9a4047bcde4a9dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=2.0, min=-2.0), FloatSlider(value=0.0, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plot = interactive(\n",
    "    plot_interactive, \n",
    "    w=(-2.0, 2.0), \n",
    "    b=(-3, 3, 0.5), \n",
    "    func=fixed(sigmoid)\n",
    ")\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = \\frac{e^x - e^{-x}}{e^x+e^{-x}}$$\n",
    "\n",
    "$$y^\\prime = 1 - y^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left(\\frac{f}{g}\\right)^\\prime = \\frac{f^\\prime\\cdot g - g^\\prime\\cdot f}{g^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f = e^x - e^{-x} \\implies f^\\prime = e^x - (-1)e^{-x} = e^x + e^{-x} \\\\\n",
    "g = e^x + e^{-x} \\implies g^\\prime = e^x + (-1)e^{-x} = e^x - e^{-x}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y^\\prime \n",
    "&= \\frac{(e^x + e^{-x})(e^x + e^{-x}) - (e^x - e^{-x})(e^x - e^{-x}) }{(e^x+e^{-x})^2}\\\\\n",
    "&= \\left(\\frac{e^x + e^{-x}}{e^x+e^{-x}}\\right)^2 - \\left(\\frac{e^x - e^{-x}}{e^x+e^{-x}}\\right)^2\\\\\n",
    "&= 1 - y^2\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x, derivative=False):\n",
    "    y = (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
    "    return 1-y**2 if derivative else y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edb4788ef69447b9bbe0f34917b53c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=2.0, min=-2.0), FloatSlider(value=0.0, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plot = interactive(\n",
    "    plot_interactive, \n",
    "    w=(-2.0, 2.0), \n",
    "    b=(-3, 3, 0.5), \n",
    "    func=fixed(tanh), \n",
    "    ylim=fixed((-2, 2))\n",
    ")\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rectified Linear Unit (ReLU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = max(0, x)$$\n",
    "\n",
    "$$y = \\begin{cases}0 &,\\  x \\leq 0\\\\x &,\\ x > 0\\end{cases}$$\n",
    "\n",
    "$$\\frac{\\partial y}{\\partial x} = \\begin{cases}0 &,\\  x \\leq 0\\\\1 &,\\ x > 0\\end{cases}$$\n",
    "\n",
    "__Obs.__: Lembrando que a derivada da ReLU quando x = 0 não existe matematicamente, mas é convencionalmente definida como 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x, derivative=False):\n",
    "    if derivative:\n",
    "        return np.where(x<=0, 0, 1)\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41cc5dfb4d774aadbaedd968e22841a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=2.0, min=-2.0), FloatSlider(value=0.0, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plot = interactive(\n",
    "    plot_interactive, \n",
    "    w=(-2.0, 2.0), \n",
    "    b=(-3, 3, 0.5), \n",
    "    func=fixed(relu), \n",
    "    ylim=fixed((-1, 10))\n",
    ")\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaky ReLU "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = \\begin{cases}\\alpha x &,\\ x \\leq 0\\\\x &,\\ x > 0\\end{cases}$$\n",
    "\n",
    "$$\\frac{\\partial y}{\\partial x} = \\begin{cases}\\alpha &,\\  x \\leq 0\\\\1 &,\\  x > 0\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(x, derivative=False):\n",
    "    alpha = 0.1\n",
    "    if derivative:\n",
    "        return np.where(x<=0, alpha, 1)\n",
    "    return np.where(x<=0, alpha*x, x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457165bbcd214fec87bc85df1c823113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=2.0, min=-2.0), FloatSlider(value=0.0, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plot = interactive(\n",
    "    plot_interactive, \n",
    "    w=(-2.0, 2.0), \n",
    "    b=(-3, 3, 0.5), \n",
    "    func=fixed(leaky_relu), \n",
    "    ylim=fixed((-1, 10))\n",
    ")\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential Linear Unit (eLU) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = \\begin{cases}\\alpha(e^x -1) &,\\ x \\leq 0\\\\x &,\\ x > 0\\end{cases}$$\n",
    "\n",
    "$$\\frac{\\partial y}{\\partial x} = \\begin{cases}y + \\alpha &,\\  x \\leq 0\\\\1 &,\\  x > 0\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(x, derivative=False):\n",
    "    alpha = 1.0\n",
    "    if derivative:\n",
    "        y = elu(x)\n",
    "        return np.where(x<=0, y+alpha, 1)\n",
    "    return np.where(x<=0, alpha*(np.exp(x)-1), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce230537365247d2bab513e86bb5dafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='w', max=2.0, min=-2.0), FloatSlider(value=0.0, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_plot = interactive(\n",
    "    plot_interactive, \n",
    "    w=(-2.0, 2.0), \n",
    "    b=(-3, 3, 0.5), \n",
    "    func=fixed(elu), \n",
    "    ylim=fixed((-2, 10))\n",
    ")\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabela das Funções de Ativação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/funcoes_de_ativacao.png\" width='700'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Tabela das funções de ativação](https://en.wikipedia.org/wiki/Activation_function)\n",
    "- [Towards Data Science](https://medium.com/towards-data-science/activation-functions-neural-networks-1cbd9f8d91d6)\n",
    "- [Stack Exchange](https://stats.stackexchange.com/questions/115258/comprehensive-list-of-activation-functions-in-neural-networks-with-pros-cons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "state": {
    "568cf18b31b04b14b5b59379918b64e2": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "58032045773043aeb5dab953be590b44": {
     "views": [
      {
       "cell_index": 30
      }
     ]
    },
    "743ccf7c641c485e9250b2558be149d1": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    },
    "a41e4be364004b0d924d05e304ee3bcb": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    },
    "bbf702b6ba494528a2233c691e2bd6d9": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "c259af61fd66413783ae3ed1e32ece47": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "c7f3128cf6d8492795e406ed70fa7e07": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
